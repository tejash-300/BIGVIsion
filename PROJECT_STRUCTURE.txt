VIDEO CLASSIFICATION PROJECT STRUCTURE
======================================

video-classification-project/
â”‚
â”œâ”€â”€ ğŸ“ configs/
â”‚   â””â”€â”€ config.yaml                  # Main configuration file
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/                         # Original video files
â”‚   â”œâ”€â”€ processed/                   # Preprocessed data (optional)
â”‚   â””â”€â”€ splits/                      # Train/val/test split files
â”‚       â”œâ”€â”€ train.json
â”‚       â”œâ”€â”€ val.json
â”‚       â”œâ”€â”€ test.json
â”‚       â””â”€â”€ class_names.json
â”‚
â”œâ”€â”€ ğŸ“ models/                       # Saved model checkpoints
â”‚   â”œâ”€â”€ best_model.pth
â”‚   â””â”€â”€ checkpoint_epoch_*.pth
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                    # Jupyter notebooks (MAIN SCRIPTS)
â”‚   â”œâ”€â”€ 01_data_preprocessing_and_exploration.ipynb
â”‚   â”œâ”€â”€ 02_model_training.ipynb
â”‚   â”œâ”€â”€ 03_evaluation_and_visualization.ipynb
â”‚   â””â”€â”€ 04_inference_and_prediction.ipynb
â”‚
â”œâ”€â”€ ğŸ“ utils/                        # Utility modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_utils.py               # Data loading & preprocessing
â”‚   â”œâ”€â”€ model_utils.py              # Model creation & management
â”‚   â”œâ”€â”€ training_utils.py           # Training & evaluation functions
â”‚   â””â”€â”€ visualization_utils.py      # Plotting & visualization
â”‚
â”œâ”€â”€ ğŸ“ outputs/
â”‚   â”œâ”€â”€ logs/                       # Training logs & TensorBoard
â”‚   â”œâ”€â”€ visualizations/             # Generated plots & figures
â”‚   â”‚   â”œâ”€â”€ training_history.png
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚   â””â”€â”€ per_class_metrics.png
â”‚   â””â”€â”€ predictions/                # Prediction results
â”‚       â”œâ”€â”€ predictions.json
â”‚       â””â”€â”€ predictions.csv
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt              # Python dependencies
â”œâ”€â”€ ğŸ“„ README.md                     # Comprehensive documentation
â”œâ”€â”€ ğŸ“„ QUICKSTART.md                # Quick start guide
â””â”€â”€ ğŸ“„ PROJECT_STRUCTURE.txt        # This file

KEY FILES DESCRIPTION
=====================

CONFIGURATION:
- config.yaml: All project settings (model, training, data, etc.)

NOTEBOOKS (Execute in Order):
1. Data Preprocessing: Load data, create splits, visualize
2. Model Training: Train VideoMAE/TimeSformer with monitoring
3. Evaluation: Test performance, confusion matrix, metrics
4. Inference: Make predictions on new videos

UTILITIES:
- data_utils.py: VideoDataset class, data loaders, preprocessing
- model_utils.py: Model creation, checkpoint management
- training_utils.py: Training loops, metrics, evaluation
- visualization_utils.py: Plotting functions for results

FEATURES
========
âœ… State-of-the-art models (VideoMAE, TimeSformer, I3D)
âœ… Mixed precision training (FP16)
âœ… Data augmentation pipeline
âœ… Comprehensive evaluation metrics
âœ… Beautiful visualizations
âœ… Export predictions (JSON/CSV)
âœ… Real-time webcam inference
âœ… Production-ready code

WORKFLOW
========
1. Configure (config.yaml)
2. Prepare data (Notebook 01)
3. Train model (Notebook 02)
4. Evaluate (Notebook 03)
5. Deploy (Notebook 04)

SUPPORTED MODELS
================
- VideoMAE: Masked Autoencoding for Videos
- TimeSformer: Divided Space-Time Attention
- I3D: Inflated 3D ConvNets

DATASET
=======
Default: UCF101 (101 action classes, 13K videos)
Custom: Any video classification dataset

REQUIREMENTS
============
- Python 3.8+
- PyTorch 2.0+
- transformers, timm
- opencv, decord
- See requirements.txt for complete list

